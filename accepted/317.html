<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<TITLE>Preliminary Program</TITLE>

<style>

BODY {
   MARGIN-TOP: 15pt;
   MARGIN-LEFT: 15pt;
   MARGIN-RIGHT: 15pt;
   MARGIN-BOTTOM: 15pt;
   FONT-SIZE: 10pt;
   FONT-FAMILY: "Times New Roman";
   BACKGROUND-COLOR: #ffffff;
   COLOR: #000000;
}

P {
   FONT-SIZE: 10pt;
}

TD {
   FONT-SIZE: 10pt;
}

TH {
   FONT-SIZE: 10pt;
}


A {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}
A:visited {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}
A:active {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
   TEXT-DECORATION: none
}
A:hover {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
   TEXT-DECORATION: underline
}
H4 {
   FONT-SIZE: 10pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H3 {
   FONT-SIZE: 11pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H2 {
   FONT-SIZE: 12pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H1 {
   FONT-SIZE: 14pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

</style>

<p>

<h4>Idest: Learning a Distributed Representation for Event Patterns</h4>

<em>Sebastian Krause<sup>1</sup>,&nbsp;Enrique Alfonseca<sup>2</sup>,&nbsp;Katja Filippova<sup>2</sup>,&nbsp;Daniele Pighin<sup>3</sup></em><br>
<sup>1</sup>German Research Center for Artificial Intelligence, <sup>2</sup>Google, <sup>3</sup>Google Inc

<p>

<hr>


<h4>Abstract</h4>

<blockquote>
    <p>This paper describes Idest, a new method for learning paraphrases of event patterns. It is based on a new neural network architecture that only relies on the weak supervision signal that comes from the news published on the same day and mention the same real-world entities. It can generalize across extractions from different dates to produce a robust paraphrase model for event patterns that can also capture meaningful representations for rare patterns. We compare it with two state-of-the-art systems and show that it can attain comparable quality when trained on a small dataset. Its generalization capabilities also allow it to leverage much more data, leading to substantial quality improvements. </p>
</blockquote>




<hr>

<p>
</body>
</html>