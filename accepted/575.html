<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<TITLE>Preliminary Program</TITLE>

<style>

BODY {
   MARGIN-TOP: 15pt;
   MARGIN-LEFT: 15pt;
   MARGIN-RIGHT: 15pt;
   MARGIN-BOTTOM: 15pt;
   FONT-SIZE: 10pt;
   FONT-FAMILY: "Times New Roman";
   BACKGROUND-COLOR: #ffffff;
   COLOR: #000000;
}

P {
   FONT-SIZE: 10pt;
}

TD {
   FONT-SIZE: 10pt;
}

TH {
   FONT-SIZE: 10pt;
}


A {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}
A:visited {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}
A:active {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
   TEXT-DECORATION: none
}
A:hover {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
   TEXT-DECORATION: underline
}
H4 {
   FONT-SIZE: 10pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H3 {
   FONT-SIZE: 11pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H2 {
   FONT-SIZE: 12pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H1 {
   FONT-SIZE: 14pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

</style>

<p>

<h4>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</h4>

<em>Alessandro Sordoni<sup>1</sup>,&nbsp;Michel Galley<sup>2</sup>,&nbsp;Michael Auli<sup>3</sup>,&nbsp;Chris Brockett<sup>2</sup>,&nbsp;Yangfeng Ji<sup>4</sup>,&nbsp;Margaret Mitchell<sup>2</sup>,&nbsp;Jian-Yun Nie<sup>1</sup>,&nbsp;Jianfeng Gao<sup>2</sup>,&nbsp;Bill Dolan<sup>2</sup></em><br>
<sup>1</sup>Université de Montréal, <sup>2</sup>Microsoft, <sup>3</sup>Facebook, <sup>4</sup>Georgia Tech

<p>

<hr>


<h4>Abstract</h4>

<blockquote>
    <p>We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations.  A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models, allowing the system to take into account previous dialog utterances. Our dynamic-context generative models show consistent gains over both context-sensitive and non-context-sensitive Machine Translation and Information Retrieval baselines. </p>
</blockquote>




<hr>

<p>
</body>
</html>