<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<TITLE>Preliminary Program</TITLE>

<style>

BODY {
   MARGIN-TOP: 15pt;
   MARGIN-LEFT: 15pt;
   MARGIN-RIGHT: 15pt;
   MARGIN-BOTTOM: 15pt;
   FONT-SIZE: 10pt;
   FONT-FAMILY: "Times New Roman";
   BACKGROUND-COLOR: #ffffff;
   COLOR: #000000;
}

P {
   FONT-SIZE: 10pt;
}

TD {
   FONT-SIZE: 10pt;
}

TH {
   FONT-SIZE: 10pt;
}


A {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}
A:visited {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}
A:active {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
   TEXT-DECORATION: none
}
A:hover {
   COLOR: #32426c;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
   TEXT-DECORATION: underline
}
H4 {
   FONT-SIZE: 10pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H3 {
   FONT-SIZE: 11pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H2 {
   FONT-SIZE: 12pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

H1 {
   FONT-SIZE: 14pt;
   FONT-FAMILY: Arial, Helvetica, sans-serif;
}

</style>

<p>

<h4>Random Walks and Neural Network Language Models on Knowledge Bases</h4>

<em>Josu Goikoetxea<sup>1</sup>,&nbsp;Aitor Soroa<sup>2</sup>,&nbsp;Eneko Agirre<sup>3</sup></em><br>
<sup>1</sup>University of the Basque Country, <sup>2</sup>assistant lecturer, <sup>3</sup>University of the Basque Country (UPV/EHU)

<p>

<hr>


<h4>Abstract</h4>

<blockquote>
    <p>Random walks over large knowledge bases like WordNet have been   successfully used in word similarity, relatedness and disambiguation   tasks. Unfortunately, those algorithms are relatively slow for large   repositories, with significant memory footprints. In this paper we   present a novel algorithm which encodes the structure of a knowledge   base in a continuous vector space, combining random walks and neural   net language models in order to produce novel word   representations. Evaluation in word relatedness and similarity   datasets yields equal or better results than those of a random walk   algorithm, using a dense representation &#40;300 dimensions instead of   117K&#41;. Furthermore, the word representations are complementary to   those of the random walk algorithm and to corpus-based continuous   representations, improving the state-of-the-art in the similarity   dataset. Our technique opens up exciting opportunities to combine   distributional and knowledge-based word representations. </p>
</blockquote>




<hr>

<p>
</body>
</html>